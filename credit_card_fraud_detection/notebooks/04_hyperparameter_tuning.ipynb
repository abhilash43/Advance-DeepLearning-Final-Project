{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2a27861",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning — Random Forest\n",
    "\n",
    "This notebook performs baseline training, hyperparameter tuning using RandomizedSearchCV, and final evaluation for a RandomForestClassifier on the credit card fraud detection dataset. All cells are self-contained and `random_state=42` is used everywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341b91f0",
   "metadata": {},
   "source": [
    "## 1) Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50988574",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import (recall_score, precision_score, f1_score, roc_auc_score, average_precision_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51012479",
   "metadata": {},
   "source": [
    "## 2) Load data and print shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68a37f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train (170883, 30)\n",
      "y_train (170883,)\n",
      "X_val (28481, 30)\n",
      "y_val (28481,)\n",
      "X_test (85443, 30)\n",
      "y_test (85443,)\n"
     ]
    }
   ],
   "source": [
    "# Paths (notebook lives in `notebooks/`)\n",
    "data_dir = os.path.join('..', 'data', 'processed')\n",
    "X_train = np.load(os.path.join(data_dir, 'X_train_transformed.npy'))\n",
    "X_val = np.load(os.path.join(data_dir, 'X_val_transformed.npy'))\n",
    "X_test = np.load(os.path.join(data_dir, 'X_test_transformed.npy'))\n",
    "y_train = np.load(os.path.join(data_dir, 'y_train.npy'))\n",
    "y_val = np.load(os.path.join(data_dir, 'y_val.npy'))\n",
    "y_test = np.load(os.path.join(data_dir, 'y_test.npy'))\n",
    "print('X_train', X_train.shape)\n",
    "print('y_train', y_train.shape)\n",
    "print('X_val', X_val.shape)\n",
    "print('y_val', y_val.shape)\n",
    "print('X_test', X_test.shape)\n",
    "print('y_test', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f345f55",
   "metadata": {},
   "source": [
    "## 3) Baseline Random Forest (n_estimators=100) — Evaluate on VALIDATION set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0813fd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline (validation) metrics:\n",
      "{'recall': 0.7959183673469388, 'precision': 0.975, 'f1': 0.8764044943820225, 'roc_auc': np.float64(0.9580944293868363), 'pr_auc': np.float64(0.8678746782602694)}\n"
     ]
    }
   ],
   "source": [
    "# Helper to compute metrics\n",
    "def compute_metrics(y_true, y_pred, y_proba):\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    roc = roc_auc_score(y_true, y_proba[:, 1])\n",
    "    pr = average_precision_score(y_true, y_proba[:, 1])\n",
    "    return {\n",
    "        'recall': rec,\n",
    "        'precision': prec,\n",
    "        'f1': f1,\n",
    "        'roc_auc': roc,\n",
    "        'pr_auc': pr\n",
    "    }\n",
    "\n",
    "# Baseline model\n",
    "baseline_clf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42, n_jobs=-1)\n",
    "baseline_clf.fit(X_train, y_train)\n",
    "y_val_pred_baseline = baseline_clf.predict(X_val)\n",
    "y_val_proba_baseline = baseline_clf.predict_proba(X_val)\n",
    "metrics_baseline_val = compute_metrics(y_val, y_val_pred_baseline, y_val_proba_baseline)\n",
    "print('Baseline (validation) metrics:')\n",
    "print(metrics_baseline_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b46ff",
   "metadata": {},
   "source": [
    "## 4) Hyperparameter tuning with RandomizedSearchCV\n",
    "- `RandomizedSearchCV` is used because it's much faster than grid search for large search spaces.\n",
    "- `cv=3`, `n_iter=15`, `scoring='f1'`, `random_state=42`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "81a16d29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "RANDOM FOREST HYPERPARAMETER TUNING (REDUCED & STABLE)\n",
      "======================================================================\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 1.9min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.1min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.4min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 4.7min\n",
      "[CV] END max_depth=30, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.7min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  47.7s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  51.0s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  52.6s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  58.4s\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time= 1.9min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 4.5min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=1, min_samples_split=5, n_estimators=200; total time= 2.5min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 2.9min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.0min\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=1, min_samples_split=2, n_estimators=300; total time= 3.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.8min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=None, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 1.8min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=15, max_features=sqrt, min_samples_leaf=2, min_samples_split=5, n_estimators=200; total time= 2.0min\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  47.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  52.1s\n",
      "[CV] END max_depth=None, max_features=log2, min_samples_leaf=1, min_samples_split=2, n_estimators=100; total time=  47.2s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  55.5s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  54.8s\n",
      "[CV] END max_depth=30, max_features=sqrt, min_samples_leaf=2, min_samples_split=2, n_estimators=100; total time=  58.0s\n",
      "\n",
      "✓ RandomizedSearchCV completed successfully\n",
      "✓ Runtime: 3504.2 seconds\n",
      "\n",
      "BEST HYPERPARAMETERS:\n",
      "  n_estimators        : 100\n",
      "  min_samples_split   : 2\n",
      "  min_samples_leaf    : 2\n",
      "  max_features        : log2\n",
      "  max_depth           : None\n",
      "\n",
      "Best CV F1-Score: 0.8423\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# FAST & STABLE RANDOMIZED SEARCH (WINDOWS-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "import time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"RANDOM FOREST HYPERPARAMETER TUNING (REDUCED & STABLE)\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Define reduced hyperparameter search space\n",
    "param_distributions = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 15, 30],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Base Random Forest model\n",
    "base_rf = RandomForestClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Stratified CV (important for imbalance)\n",
    "cv_strategy = StratifiedKFold(\n",
    "    n_splits=3,\n",
    "    shuffle=True,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Randomized Search\n",
    "rsearch = RandomizedSearchCV(\n",
    "    estimator=base_rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=10,              # reduced for speed\n",
    "    scoring='f1',           # correct metric for fraud detection\n",
    "    cv=cv_strategy,\n",
    "    random_state=42,\n",
    "    n_jobs=1,               # IMPORTANT: Windows stability\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Run tuning\n",
    "start_time = time.time()\n",
    "rsearch.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "# Best model\n",
    "tuned_model = rsearch.best_estimator_\n",
    "\n",
    "print(\"\\n✓ RandomizedSearchCV completed successfully\")\n",
    "print(f\"✓ Runtime: {end_time - start_time:.1f} seconds\")\n",
    "\n",
    "print(\"\\nBEST HYPERPARAMETERS:\")\n",
    "for k, v in rsearch.best_params_.items():\n",
    "    print(f\"  {k:20s}: {v}\")\n",
    "\n",
    "print(f\"\\nBest CV F1-Score: {rsearch.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745a588",
   "metadata": {},
   "source": [
    "## 5) Compare Baseline vs Tuned (VALIDATION metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b371ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "model",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "f1",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "roc_auc",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "pr_auc",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "ref": "79aef530-3d49-41c4-9e5b-31bc0313d4c0",
       "rows": [
        [
         "baseline",
         "0.7959183673469388",
         "0.975",
         "0.8764044943820225",
         "0.9580944293868363",
         "0.8678746782602694"
        ],
        [
         "tuned",
         "0.7755102040816326",
         "0.926829268292683",
         "0.8444444444444444",
         "0.988114139859658",
         "0.8728688883595278"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recall</th>\n",
       "      <th>precision</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>pr_auc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>baseline</th>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.876404</td>\n",
       "      <td>0.958094</td>\n",
       "      <td>0.867875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tuned</th>\n",
       "      <td>0.775510</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.844444</td>\n",
       "      <td>0.988114</td>\n",
       "      <td>0.872869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            recall  precision        f1   roc_auc    pr_auc\n",
       "model                                                      \n",
       "baseline  0.795918   0.975000  0.876404  0.958094  0.867875\n",
       "tuned     0.775510   0.926829  0.844444  0.988114  0.872869"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate tuned model on validation set\n",
    "y_val_pred_tuned = tuned_model.predict(X_val)\n",
    "y_val_proba_tuned = tuned_model.predict_proba(X_val)\n",
    "metrics_tuned_val = compute_metrics(y_val, y_val_pred_tuned, y_val_proba_tuned)\n",
    "\n",
    "comparison_df = pd.DataFrame([\n",
    "    dict(model='baseline', **metrics_baseline_val),\n",
    "    dict(model='tuned', **metrics_tuned_val)\n",
    "])\n",
    "comparison_df = comparison_df.set_index('model')\n",
    "comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f22eaa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved validation comparison to ..\\results\\metrics\\rf_tuning_comparison.csv\n"
     ]
    }
   ],
   "source": [
    "# Ensure results dir exists and save comparison\n",
    "results_dir = os.path.join('..', 'results')\n",
    "metrics_dir = os.path.join(results_dir, 'metrics')\n",
    "os.makedirs(metrics_dir, exist_ok=True)\n",
    "comparison_csv_path = os.path.join(metrics_dir, 'rf_tuning_comparison.csv')\n",
    "comparison_df.to_csv(comparison_csv_path)\n",
    "print('Saved validation comparison to', comparison_csv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fe4820",
   "metadata": {},
   "source": [
    "## 6) Final evaluation on TEST set (only once)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d40d40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned model (test) metrics:\n",
      "{'recall': 0.7297297297297297, 'precision': 0.9391304347826087, 'f1': 0.8212927756653993, 'roc_auc': np.float64(0.9401630351261043), 'pr_auc': np.float64(0.8202488637943746)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on test set\n",
    "y_test_pred = tuned_model.predict(X_test)\n",
    "y_test_proba = tuned_model.predict_proba(X_test)\n",
    "metrics_tuned_test = compute_metrics(y_test, y_test_pred, y_test_proba)\n",
    "print('Tuned model (test) metrics:')\n",
    "print(metrics_tuned_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10af105a",
   "metadata": {},
   "source": [
    "## 7) Save tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d72ebad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tuned model to ..\\results\\random_forest_tuned_model.pkl\n",
      "Saved test metrics to ..\\results\\metrics\\rf_tuned_test_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "# Save tuned model artifact\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "model_path = os.path.join(results_dir, 'random_forest_tuned_model.pkl')\n",
    "joblib.dump(tuned_model, model_path)\n",
    "print('Saved tuned model to', model_path)\n",
    "# Save test metrics alongside if desired\n",
    "test_metrics_path = os.path.join(metrics_dir, 'rf_tuned_test_metrics.csv')\n",
    "pd.DataFrame([dict(model='tuned_test', **metrics_tuned_test)]).set_index('model').to_csv(test_metrics_path)\n",
    "print('Saved test metrics to', test_metrics_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2377aa1b",
   "metadata": {},
   "source": [
    "## 8) Explanations\n",
    "\n",
    "**Why RandomizedSearchCV:** RandomizedSearchCV explores a wide hyperparameter space using a fixed number of iterations (`n_iter=15`) and is far faster than GridSearchCV for large search spaces while still finding strong configurations.\n",
    "\n",
    "**Why F1 / PR-AUC:** For highly imbalanced classification, F1 balances precision and recall and focuses on the minority (fraud) class. PR-AUC (average precision) better reflects performance on imbalanced data than ROC-AUC because it emphasizes precision for the positive class.\n",
    "\n",
    "**How data leakage is avoided:** All preprocessing was applied earlier and saved as transformed numpy arrays. This notebook only loads the preprocessed `X_train`, `X_val`, `X_test` and uses `X_train` for fitting/tuning and `X_val` for validation — the test set is used only once at the end. No information from `X_val` or `X_test` is used during fitting or hyperparameter selection beyond intended validation/evaluation steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
